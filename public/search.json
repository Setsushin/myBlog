[{"title":"Obtain MAX/MIN values or indexes from any column/row","url":"/2021/10/29/Obtain%20MAX%20or%20MIN%20values%20or%20indexes%20from%20any%20column%20or%20row/","content":"This post introduces some common operations of obtaining MAX/MIN values or indexes from any column/row.Yes, it’s very basic. But reviewing is not bad, always.\nprevious:import pandasdf = pandas.dataframe(data)  \nObtain the MAX/MIN value of one column:  \ndf[‘column_name’].max()df[‘column_name’].min()\n\nObtain the MAX/MIN value indexes of one column:  \ndf[‘column_name’].idxmax()df[‘column_name’].idxmin()\n\nYou need to use loc/iloc, if you want to deal from “row”:Obtain the MAX/MIN value of one row:  \ndf.loc[‘row_name’].max()df.loc[‘row_name’].min()\nor:  \ndf.iloc[row_index].max()df.iloc[row_index].min()\n\nObtain the MAX/MIN value indexes of one row:  \ndf.loc[‘row_name’].idxmax()df.loc[‘row_name’].idxmin()\nor:  \ndf.iloc[row_index].idxmax()df.iloc[row_index].idxmin()\n","categories":["Technologies"],"tags":["Python","Pandas","DataSciences"]},{"title":"fillna函数中axis字段的方向问题","url":"/2021/10/29/fillna%E5%87%BD%E6%95%B0%E4%B8%ADaxis%E5%AD%97%E6%AE%B5%E7%9A%84%E6%96%B9%E5%90%91%E9%97%AE%E9%A2%98/","content":"在使用Pandas时，如果想要填充某个dataframe中的缺失值NaN，可以使用fillna函数。fillna函数有两个常用字段：method和axis。如果用固定值填充，可以直接使用fillna(n)，其中n代表要使用的填充值。如果要使用method，有两种可用方法：bfill/backfill和ffill/pad。其中：bfill/backfill使用下一个有效值填充ffill/pad使用前一个有效值填充  \n例子如下：使用pad方法填充reviews中的缺失值：  \nreviews = pd.DataFrame([[np.nan, 2, np.nan, 0],                   [3, 4, np.nan, 1],                   [np.nan, np.nan, np.nan, 5],                   [np.nan, 3, np.nan, 4]],                  columns=list(&quot;ABCD&quot;))\n\n按照逻辑，填充值应该来自于同一列，所以axis应该为1，对吗？让我们试试看：  \nreviews.fillna(method = &#x27;pad&#x27;, axis = 1)\n完全不对！让我们把axis换成0再试一次。  \nreviews.fillna(method = &#x27;pad&#x27;, axis = 0)\n正确的axis是0。实际上，如果我们去掉axis字段使用默认值，我们也会得到axis=0的结果。  \n所以，在fillna函数中：默认或axis = 0：沿纵向获取有效值填充axis = 1：沿横向获取有效值填充\n这里的axis可能并不是“获取数值的方向”，而是“填充数值的推进方向”。比如axis=0时，数值填充是按列处理的，但在整体角度，推进方向是沿axis=0前进的。这可能有点反直觉，但我们最好还是记住这件它。  \n","categories":["Technologies"],"tags":["Python","Pandas","DataSciences"]},{"title":"The fall of Kosugi","url":"/2021/11/03/The-fall-of-Kosugi/","content":"そもそも秋ですね。小杉の秋めっちゃ綺麗！\n\n\n\n\n\n秋の気分たっぷりでしょう。\n","categories":["Life"]},{"title":"Why you should always use \"guard\"","url":"/2021/11/03/Why%20you%20should%20always%20use%20%22guard%22/","content":"You must ever been tormented by multiple nested if-else statements, like following:  \nif (case1):\tif (case2):\t\tif (case3):\t\t\tdo something\t\telse:\t\t\tbreak\n\nYes, for poor linear thinking of the programmer, it’s very natural.However, the fact is that even the author himself, he will forget all logics when he reviews after only a few days.So if you want to implement the above logic, it’s strongly recommended to use “gurad”, like this:  \nif (not case1):\tbreakif (not case2):\tbreakif (not case3)\tbreakdo something\nwhich makes everyone who is trying to continue working based on your codes happier.\n","categories":["Technologies"],"tags":["Programming","python"]},{"title":"A SQL \"expert finder\" function","url":"/2021/11/09/expert-finder/","content":"Returns a DataFrame with the user IDs who have written Stack Overflow answers on a specific topic.Inputs:topic: A string with the topic of interestclient: A Client object that specifies the connection to the Stack Overflow dataset  \nOutputs:results: A DataFrame with columns for user_id and number_of_answers.  \ndef expert_finder(topic, client):    my_query = &quot;&quot;&quot;               SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers               FROM `bigquery-public-data.stackoverflow.posts_questions` AS q               INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a                   ON q.id = a.parent_Id               WHERE q.tags like &#x27;%&#123;topic&#125;%&#x27;               GROUP BY a.owner_user_id               ORDER BY number_of_answers DESC               &quot;&quot;&quot;    # Set up the query (a real service would have good error handling for     # queries that scan too much data)    safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)          my_query_job = client.query(my_query, job_config=safe_config)    # API request - run the query, and return a pandas DataFrame    results = my_query_job.to_dataframe()    return results\n","tags":["python","SQL"]}]